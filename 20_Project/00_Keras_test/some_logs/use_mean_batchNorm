use same model, replace to the substract mean and add batch norm

/home/freshield/anaconda2/bin/python /media/freshield/BUFFER/LEARN_TENSORFLOW/Project/Keras_test/tf_change_input.py
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
Data Shape: (10000, 6261)
(8000, 31, 100, 3)
(1000, 31, 100, 3)
(8000,)
(1000,)
85.0551108496
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
-37.1971891504
float64
float64
-------------------now changed-----------------
lr_rate is 0.01
reg is 0
------------------------------------------------
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.645
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.22GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
loss in step 0 is 1.688819
last 500 loop use 297.025561 sec
rest time is 99.008520 minutes
----------train acc in step 0 is 0.336125-------------
----------accuracy in step 0 is 0.327000-------------
loss in step 100 is 1.382166
loss in step 200 is 1.332137
loss in step 300 is 1.261786
loss in step 400 is 1.196011
loss in step 500 is 1.143973
last 500 loop use 19.159913 sec
rest time is 6.067306 minutes
----------train acc in step 500 is 0.322250-------------
----------accuracy in step 500 is 0.333000-------------
loss in step 600 is 1.302052
loss in step 700 is 1.200838
loss in step 800 is 1.238048
loss in step 900 is 1.240545
loss in step 1000 is 1.224719
last 500 loop use 21.512985 sec
rest time is 6.453896 minutes
----------train acc in step 1000 is 0.340000-------------
----------accuracy in step 1000 is 0.339000-------------
loss in step 1100 is 1.106831
loss in step 1200 is 1.203483
loss in step 1300 is 1.161544
loss in step 1400 is 1.189709
loss in step 1500 is 1.170795
last 500 loop use 19.104004 sec
rest time is 5.412801 minutes
----------train acc in step 1500 is 0.334500-------------
----------accuracy in step 1500 is 0.341000-------------
loss in step 1600 is 1.176183
loss in step 1700 is 0.936283
loss in step 1800 is 0.840452
loss in step 1900 is 0.535114
loss in step 2000 is 0.240042
last 500 loop use 19.062519 sec
rest time is 5.083338 minutes
----------train acc in step 2000 is 0.334375-------------
----------accuracy in step 2000 is 0.339000-------------
loss in step 2100 is 0.315361
loss in step 2200 is 0.087327
loss in step 2300 is 0.135141
loss in step 2400 is 0.127297
loss in step 2500 is 0.283144
last 500 loop use 19.016504 sec
rest time is 4.754126 minutes
----------train acc in step 2500 is 0.334375-------------
----------accuracy in step 2500 is 0.339000-------------
loss in step 2600 is 0.162409
loss in step 2700 is 0.244784
loss in step 2800 is 0.105787
loss in step 2900 is 0.237299
loss in step 3000 is 0.787631
last 500 loop use 18.903017 sec
rest time is 4.410704 minutes
----------train acc in step 3000 is 0.421250-------------
----------accuracy in step 3000 is 0.463000-------------
loss in step 3100 is 0.129380
loss in step 3200 is 0.300150
loss in step 3300 is 0.241973
loss in step 3400 is 0.356887
loss in step 3500 is 0.078018
last 500 loop use 19.091487 sec
rest time is 4.136489 minutes
----------train acc in step 3500 is 0.342500-------------
----------accuracy in step 3500 is 0.494000-------------
loss in step 3600 is 0.255289
loss in step 3700 is 1.706449
loss in step 3800 is 0.560128
loss in step 3900 is 0.578905
loss in step 4000 is 0.728836
last 500 loop use 19.014001 sec
rest time is 3.802800 minutes
----------train acc in step 4000 is 0.343500-------------
----------accuracy in step 4000 is 0.329000-------------
loss in step 4100 is 0.764984
loss in step 4200 is 0.224916
loss in step 4300 is 0.405795
loss in step 4400 is 0.117959
loss in step 4500 is 0.669329
last 500 loop use 19.129992 sec
rest time is 3.507165 minutes
----------train acc in step 4500 is 0.334375-------------
----------accuracy in step 4500 is 0.339000-------------
loss in step 4600 is 0.107912
loss in step 4700 is 0.255769
loss in step 4800 is 0.087655
loss in step 4900 is 0.229438
loss in step 5000 is 0.197761
last 500 loop use 19.159555 sec
rest time is 3.193259 minutes
----------train acc in step 5000 is 0.551375-------------
----------accuracy in step 5000 is 0.522000-------------
loss in step 5100 is 0.237943
loss in step 5200 is 0.017437
loss in step 5300 is 0.116429
loss in step 5400 is 0.209061
loss in step 5500 is 0.017610
last 500 loop use 19.063950 sec
rest time is 2.859592 minutes
----------train acc in step 5500 is 0.334375-------------
----------accuracy in step 5500 is 0.339000-------------
loss in step 5600 is 0.013303
loss in step 5700 is 0.025059
loss in step 5800 is 0.042783
loss in step 5900 is 0.053388
loss in step 6000 is 0.235782
last 500 loop use 18.920064 sec
rest time is 2.522675 minutes
----------train acc in step 6000 is 0.334375-------------
----------accuracy in step 6000 is 0.339000-------------
loss in step 6100 is 0.011756
loss in step 6200 is 0.016137
loss in step 6300 is 0.047904
loss in step 6400 is 0.010294
loss in step 6500 is 0.058823
last 500 loop use 21.038890 sec
rest time is 2.454537 minutes
----------train acc in step 6500 is 0.954250-------------
----------accuracy in step 6500 is 0.942000-------------
loss in step 6600 is 0.038418
loss in step 6700 is 0.080931
loss in step 6800 is 0.011719
loss in step 6900 is 0.012313
loss in step 7000 is 0.005674
last 500 loop use 19.264460 sec
rest time is 1.926446 minutes
----------train acc in step 7000 is 0.415125-------------
----------accuracy in step 7000 is 0.461000-------------
loss in step 7100 is 0.155669
loss in step 7200 is 0.004544
loss in step 7300 is 0.049118
loss in step 7400 is 0.190324
loss in step 7500 is 0.011581
last 500 loop use 20.048022 sec
rest time is 1.670669 minutes
----------train acc in step 7500 is 0.334500-------------
----------accuracy in step 7500 is 0.342000-------------
loss in step 7600 is 0.042432
loss in step 7700 is 0.002566
loss in step 7800 is 0.011203
loss in step 7900 is 0.009633
loss in step 8000 is 0.007583
last 500 loop use 19.082427 sec
rest time is 1.272162 minutes
----------train acc in step 8000 is 0.334375-------------
----------accuracy in step 8000 is 0.339000-------------
loss in step 8100 is 0.278153
loss in step 8200 is 0.105192
loss in step 8300 is 0.001093
loss in step 8400 is 0.014054
loss in step 8500 is 0.001632
last 500 loop use 19.174576 sec
rest time is 0.958729 minutes
----------train acc in step 8500 is 0.994875-------------
----------accuracy in step 8500 is 0.998000-------------
loss in step 8600 is 0.004115
loss in step 8700 is 0.006591
loss in step 8800 is 0.064429
loss in step 8900 is 0.002026
loss in step 9000 is 0.008461
last 500 loop use 18.994451 sec
rest time is 0.633148 minutes
----------train acc in step 9000 is 0.785375-------------
----------accuracy in step 9000 is 0.794000-------------
loss in step 9100 is 0.069172
loss in step 9200 is 0.104633
loss in step 9300 is 0.002379
loss in step 9400 is 0.046065
loss in step 9500 is 0.043192
last 500 loop use 19.110441 sec
rest time is 0.318507 minutes
----------train acc in step 9500 is 0.334375-------------
----------accuracy in step 9500 is 0.339000-------------
loss in step 9600 is 0.022469
loss in step 9700 is 0.004079
loss in step 9800 is 0.387328
loss in step 9900 is 0.032587
last 500 loop use 20.344019 sec
rest time is 0.000678 minutes
----------train acc in step 9999 is 0.886625-------------
----------accuracy in step 9999 is 0.913000-------------
-----------last accuracy is 0.938000------------

Process finished with exit code 0
